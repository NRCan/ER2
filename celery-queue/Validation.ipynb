{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rasterio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9488d57b381a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rasterio'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format=' %(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.disable(logging.CRITICAL)\n",
    "import os\n",
    "import time\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from scipy import interpolate\n",
    "import random\n",
    "from datetime import datetime\n",
    "import math\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import sys\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format=' %(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.disable(logging.CRITICAL)\n",
    "import os\n",
    "import time\n",
    "from celery import Celery\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from scipy import interpolate\n",
    "import random\n",
    "from datetime import datetime\n",
    "import math\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import sys\n",
    "import uuid\n",
    "\n",
    "\n",
    "CELERY_BROKER_URL = os.environ.get('CELERY_BROKER_URL')\n",
    "CELERY_RESULT_BACKEND = os.environ.get('CELERY_RESULT_BACKEND')\n",
    "logging.info(\"Creating Celery instance.\")\n",
    "celery = Celery('tasks', broker=CELERY_BROKER_URL, backend=CELERY_RESULT_BACKEND)\n",
    "\n",
    "logging.info(\"Loading dependencies into memory\")\n",
    "GAT_RASTER = rasterio.open('./dependencies/dtmconditionedhandcropped_wgs841.tif')\n",
    "elevations = pd.read_csv('./dependencies/elevations_01percentiles.csv').values\n",
    "CalculationsNotPossible = pd.read_csv(\"./dependencies/calculations-not-possible.csv\")[\"CensusBloc\"].values\n",
    "ineligibleBlocks = elevations[np.isin(elevations[:, 0], CalculationsNotPossible, assume_unique=True)]\n",
    "eligibleBlocks = elevations[np.isin(elevations[:, 0], CalculationsNotPossible, assume_unique=True, invert=True)]\n",
    "\n",
    "\n",
    "# calculate damages variables below\n",
    "floodValues = pd.read_pickle(\"./dependencies/flood_values/floodValues.pkl\")\n",
    "ftDict = floodValues[\"ft\"].to_dict()\n",
    "boDict = floodValues[\"bo\"].to_dict()\n",
    "for key in ftDict.keys():\n",
    "    ftDict[key] = str(ftDict[key])\n",
    "damageCurveDict = floodValues[\"numberCode\"].to_dict()\n",
    "structureDamageDF = pd.read_pickle(\"./dependencies/structure_damage/structureDamageDF.pkl\")\n",
    "structureDamageDict = structureDamageDF.T.to_dict()\n",
    "structureDamageHeader = np.asarray(structureDamageDF.columns)\n",
    "\n",
    "contentDamageDF = pd.read_pickle(\"./dependencies/content_damage/contentDamageDF.pkl\")\n",
    "contentDamageDict = contentDamageDF.T.to_dict()\n",
    "contentDamageHeader = np.asarray(contentDamageDF.columns)\n",
    "boValuesDF = pd.read_pickle(\"./dependencies/building_occupancy/boValuesDF.pkl\")\n",
    "contentsPercentageDict = boValuesDF[\"contentsPercentage\"]\n",
    "\n",
    "adjustedBuildingValues = pd.read_pickle(\"./dependencies/building_values/adjustedBuildingValues.pkl\")\n",
    "\n",
    "eligibleBlocksDF = pd.read_pickle('./dependencies/flood_values/eligibleBlocksDF.pkl')\n",
    "eligibleBlocksDict = eligibleBlocksDF.to_dict()\n",
    "\n",
    "DB = os.environ.get('DB')\n",
    "DB_USER = os.environ.get('DB_USER')\n",
    "DB_HOST = os.environ.get('DB_HOST')\n",
    "DB_PASSWORD = os.environ.get('DB_PASSWORD')\n",
    "DB_PORT = os.environ.get('DB_PORT')\n",
    "\n",
    "cs = \"dbname=%s user=%s password=%s host=%s port=%s\" % (DB,DB_USER,DB_PASSWORD,DB_HOST,DB_PORT)\n",
    "\n",
    "FLOOD_MAP_SERVICE = os.environ.get('FLOOD_MAP_SERVICE')\n",
    "\n",
    "def get_legend_urls():\n",
    "    getCapUrl = '{FLOOD_MAP_SERVICE}&SERVICE=WMS&VERSION=1.3.0&REQUEST=GetCapabilities'.format(FLOOD_MAP_SERVICE=FLOOD_MAP_SERVICE)\n",
    "    response = requests.get(getCapUrl)\n",
    "    root = ET.fromstring(response.content)\n",
    "    legendURLs = {}\n",
    "    for layer in root.iter('{http://www.opengis.net/wms}Layer'):\n",
    "        name = layer.find('{http://www.opengis.net/wms}Name').text\n",
    "        if name != 'flood':\n",
    "            for legend in layer.iter('{http://www.opengis.net/wms}LegendURL'):\n",
    "                for legendOnlineResource in legend.iter('{http://www.opengis.net/wms}OnlineResource'):\n",
    "                    legendURLs[name] = legendOnlineResource.attrib['{http://www.w3.org/1999/xlink}href']\n",
    "    return legendURLs\n",
    "\n",
    "try:\n",
    "    legendURLs = get_legend_urls()\n",
    "except:\n",
    "    logging.error('Failed to fetch legend URLs from getCapabilities request. Falling back on default URLs.')\n",
    "    legendURLs = {\n",
    "        'affected_population': '{FLOOD_MAP_SERVICE}&version=1.3.0&service=WMS&request=GetLegendGraphic&sld_version=1.1.0&layer=affected_population&format=image/png&STYLE='.format(FLOOD_MAP_SERVICE=FLOOD_MAP_SERVICE),\n",
    "        'bldgs_affected': '{FLOOD_MAP_SERVICE}&version=1.3.0&service=WMS&request=GetLegendGraphic&sld_version=1.1.0&layer=bldgs_affected&format=image/png&STYLE='.format(FLOOD_MAP_SERVICE=FLOOD_MAP_SERVICE),\n",
    "        'gat_blocks': '{FLOOD_MAP_SERVICE}&version=1.3.0&service=WMS&request=GetLegendGraphic&sld_version=1.1.0&layer=gat_blocks&format=image/png&STYLE='.format(FLOOD_MAP_SERVICE=FLOOD_MAP_SERVICE),\n",
    "        'gat_boundary': '{FLOOD_MAP_SERVICE}&version=1.3.0&service=WMS&request=GetLegendGraphic&sld_version=1.1.0&layer=gat_boundary&format=image/png&STYLE='.format(FLOOD_MAP_SERVICE=FLOOD_MAP_SERVICE),\n",
    "        'population': '{FLOOD_MAP_SERVICE}&version=1.3.0&service=WMS&request=GetLegendGraphic&sld_version=1.1.0&layer=population&format=image/png&STYLE='.format(FLOOD_MAP_SERVICE=FLOOD_MAP_SERVICE),\n",
    "        'total_dmg': '{FLOOD_MAP_SERVICE}&version=1.3.0&service=WMS&request=GetLegendGraphic&sld_version=1.1.0&layer=total_dmg&format=image/png&STYLE='.format(FLOOD_MAP_SERVICE=FLOOD_MAP_SERVICE)\n",
    "    }\n",
    "\n",
    "@celery.task(name='tasks.get_hand_value')\n",
    "def get_hand_value(x: float, y: float):\n",
    "    # example: /tiffValue?x=-75.67502975&y=45.46843792\n",
    "    tiff_value = None\n",
    "    logging.info(\"Getting raster value\")\n",
    "    try:\n",
    "        for val in GAT_RASTER.sample([(x,y)]):\n",
    "            tiff_value = val[0]\n",
    "            if round(tiff_value,2) < -3.30:\n",
    "                return \"Out of bounds\"\n",
    "            else:\n",
    "                return str(tiff_value)\n",
    "    except:\n",
    "        return \"Out of bounds\"\n",
    "\n",
    "@celery.task(name='tasks.calculate_damages', bind=True)\n",
    "def calculate_damages(self, x, y, waterLevel):\n",
    "    conn = psycopg2.connect(cs)\n",
    "    cur = conn.cursor()\n",
    "    simId = str(uuid.uuid4())\n",
    "    siteCoordinates = {\"long\": x, \"lat\": y}\n",
    "    simulationStatus = \"ongoing\"\n",
    "    startTime = datetime.now()\n",
    "    endTime = None\n",
    "    simPercent = 0\n",
    "\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO \"flood_simulation\" (sim_id, sim_status, sim_started,\n",
    "        sim_completed, sim_percent_completed, sim_depth, sim_location_lat,\n",
    "        sim_location_long, sim_site)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, ST_SetSRID(ST_MakePoint(%s, %s),4269));\n",
    "        \"\"\",\n",
    "        (\n",
    "            simId,\n",
    "            simulationStatus,\n",
    "            startTime,\n",
    "            endTime,\n",
    "            simPercent,\n",
    "            waterLevel,\n",
    "            siteCoordinates[\"lat\"],\n",
    "            siteCoordinates[\"long\"],\n",
    "            siteCoordinates[\"long\"],\n",
    "            siteCoordinates[\"lat\"],\n",
    "        ),\n",
    "    )\n",
    "    conn.commit()\n",
    "    logging.info(\"Simulation record inserted into database\")\n",
    "\n",
    "    logging.info(\"Determining hazard...\")\n",
    "\n",
    "    eligibleBlocksFloodCriteria = eligibleBlocks[:, 1] < waterLevel\n",
    "    affectedCalcBlocks = eligibleBlocks[eligibleBlocksFloodCriteria]\n",
    "    affectedCalcBlocksIds = affectedCalcBlocks[:, 0].view().astype(np.int64)\n",
    "    affectedCalcBlocksElevations = affectedCalcBlocks[:, 1:].view()\n",
    "\n",
    "    ineligibleBlocksFloodCriteria = ineligibleBlocks[:, 1] < waterLevel\n",
    "    affectedButNotCalculatableBlocks = ineligibleBlocks[ineligibleBlocksFloodCriteria][\n",
    "        :, 0\n",
    "    ]\n",
    "    highestGroundElevation = affectedCalcBlocksElevations[:, -1]\n",
    "    lowestGroundElevation = affectedCalcBlocksElevations[:, 0]\n",
    "    highestFloodDepths = waterLevel - lowestGroundElevation\n",
    "    lowestFloodDepth = waterLevel - highestGroundElevation\n",
    "\n",
    "    lowestFloodDepth[lowestFloodDepth < 0] = 0\n",
    "\n",
    "    interpolationStart = highestGroundElevation.copy()\n",
    "    interpolationStart[lowestFloodDepth == 0] = waterLevel\n",
    "\n",
    "    intervalStep = -0.3048\n",
    "    interpolationPoints = []\n",
    "\n",
    "    startStop = list(zip(interpolationStart, lowestGroundElevation))\n",
    "    for start, stop in startStop:\n",
    "        singleInterpSet = np.arange(start, stop, intervalStep)\n",
    "        interpolationPoints.append(singleInterpSet)\n",
    "\n",
    "    groundPercentY = np.arange(0, 100.011, 0.1)\n",
    "    allCumCoverages = []\n",
    "    allDepths = []\n",
    "\n",
    "    for i, blockElevationProfile in enumerate(affectedCalcBlocksElevations):\n",
    "        x = blockElevationProfile\n",
    "        y = groundPercentY\n",
    "        f = interpolate.interp1d(x, y)\n",
    "        interpolationSet = interpolationPoints[i]\n",
    "        cumulativeCoverage = f(interpolationSet)\n",
    "        allCumCoverages.append(cumulativeCoverage)\n",
    "\n",
    "        depths = waterLevel - interpolationSet - intervalStep\n",
    "\n",
    "        highestFloodDepth = highestFloodDepths[i]\n",
    "        if depths[-1] > highestFloodDepth:\n",
    "            depths[-1] = highestFloodDepth\n",
    "\n",
    "        meterFeetConversion = 3.28084\n",
    "        depths = [round(i * meterFeetConversion, 3) for i in depths]\n",
    "        allDepths.append(depths)\n",
    "\n",
    "    numBlocksAffected = len(affectedCalcBlocksIds)\n",
    "    overallFloodedArray = np.empty((0, numBlocksAffected))\n",
    "    allCoverages = []\n",
    "\n",
    "    for cumCoverageSet in allCumCoverages:\n",
    "        coverages = []\n",
    "        for inx, val in enumerate(cumCoverageSet):\n",
    "            notLastIndex = inx < len(cumCoverageSet) - 1\n",
    "            if notLastIndex:\n",
    "                nextVal = cumCoverageSet[inx + 1]\n",
    "                adjustedValue = round(val - nextVal, 3)\n",
    "                coverages.append(adjustedValue)\n",
    "            else:\n",
    "                coverages.append(round(val, 3))\n",
    "\n",
    "        percentSum = sum(coverages)\n",
    "        if percentSum > 100.0:\n",
    "            exceedingBy = percentSum - 100.0\n",
    "            coverages[0] = round(coverages[0] - exceedingBy - 0.005, 2)\n",
    "\n",
    "        allCoverages.append(coverages)\n",
    "\n",
    "        totalFloodExtent = cumCoverageSet[0]\n",
    "        overallFloodedArray = np.append(overallFloodedArray, totalFloodExtent)\n",
    "\n",
    "    hazardDefinition = list(\n",
    "        zip(\n",
    "            [str(i) for i in affectedCalcBlocksIds.tolist()],\n",
    "            allDepths,\n",
    "            allCoverages,\n",
    "            overallFloodedArray.round(3),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    logging.info(\"Hazard defined.\")\n",
    "    logging.info(\"Determining damages...\")\n",
    "    progressOutOf = len(affectedCalcBlocksIds)\n",
    "    affectedCalcBlocksIds = [i[0] for i in hazardDefinition]\n",
    "    depths = [i[1] for i in hazardDefinition]\n",
    "    percentages = [i[2] for i in hazardDefinition]\n",
    "    overallFlooded = [i[3] for i in hazardDefinition]\n",
    "    overallFloodedDict = dict(zip(affectedCalcBlocksIds, overallFlooded))\n",
    "\n",
    "    adjInventory = adjustedBuildingValues[\n",
    "        adjustedBuildingValues.index.isin(affectedCalcBlocksIds)\n",
    "    ]\n",
    "    adjInventory.index = adjInventory.index.map(int)\n",
    "\n",
    "    depthsDict = {\n",
    "        \"0\": [np.array([x for x in depthList]) for depthList in depths],\n",
    "        \"1\": [np.array([x - 1 for x in depthList]) for depthList in depths],\n",
    "        \"3\": [np.array([x - 3 for x in depthList]) for depthList in depths],\n",
    "        \"4\": [np.array([x - 4 for x in depthList]) for depthList in depths],\n",
    "    }\n",
    "\n",
    "    wdft = depthsDict.copy()\n",
    "\n",
    "    for ftKey, ftAllValues in depthsDict.items():\n",
    "        for i, ftValue in enumerate(ftAllValues):\n",
    "            wdft[ftKey][i] = np.rint(ftValue)\n",
    "            np.place(wdft[ftKey][i], wdft[ftKey][i] > 23, 23)\n",
    "            np.place(wdft[ftKey][i], wdft[ftKey][i] < -4, -4)\n",
    "        wdft[ftKey] = dict(zip(affectedCalcBlocksIds, wdft[ftKey]))\n",
    "\n",
    "    percentagesDF = pd.DataFrame(np.asarray(percentages), index=affectedCalcBlocksIds)\n",
    "    percentagesDict = dict(zip([i for i in affectedCalcBlocksIds], percentages))\n",
    "\n",
    "    completedBlocks = []\n",
    "    def computeDamages(bldgValue, progressOutOf):\n",
    "        # Store block ID\n",
    "        blockId = str(bldgValue.name)\n",
    "\n",
    "        blockPopulation = eligibleBlocksDict['population'][blockId]\n",
    "        buildingCount = eligibleBlocksDict['bc'][blockId]\n",
    "        buildingValue = eligibleBlocksDict['bv'][blockId]\n",
    "        blockOverallFlooded = overallFloodedDict[blockId]\n",
    "\n",
    "        bldgs_affected = buildingCount * blockOverallFlooded / 100\n",
    "        affected_population = blockPopulation * blockOverallFlooded / 100\n",
    "\n",
    "\n",
    "        completedBlocks.append(blockId)\n",
    "        ticker = len(completedBlocks)\n",
    "        wp = percentagesDict[blockId]\n",
    "\n",
    "        # Only some buldings have values > than zero\n",
    "        affectedNamesList = [i[0] for i in bldgValue.index[bldgValue > 0].tolist()]\n",
    "\n",
    "        totalStructural = 0\n",
    "        totalContents = 0\n",
    "        for bldgType in affectedNamesList:\n",
    "            ft = ftDict[bldgType]\n",
    "\n",
    "            damageCurve = damageCurveDict[bldgType]\n",
    "            structureDamageValues = np.array(\n",
    "                list(structureDamageDict[damageCurve].values())\n",
    "            )\n",
    "            contentDamageValues = np.array(\n",
    "                list(contentDamageDict[damageCurve].values())\n",
    "            )\n",
    "            bldgTypeShort = boDict[bldgType]\n",
    "\n",
    "            contentsPercentage = contentsPercentageDict[bldgTypeShort] / 100\n",
    "\n",
    "            wdset = wdft[ft][blockId]\n",
    "\n",
    "            structureDic = dict(zip(structureDamageHeader, structureDamageValues))\n",
    "            contentDic = dict(zip(contentDamageHeader, contentDamageValues))\n",
    "\n",
    "            structureInterpSet = np.array([])\n",
    "            contentInterpSet = np.array([])\n",
    "\n",
    "            for wd in wdset:\n",
    "                structureInterpSet = np.append(structureInterpSet, structureDic[wd])\n",
    "                contentInterpSet = np.append(contentInterpSet, contentDic[wd])\n",
    "\n",
    "            structureSumOneBldgType = round(\n",
    "                (\n",
    "                    ((np.multiply(structureInterpSet, wp).sum()) * bldgValue[bldgType])\n",
    "                    / 10000\n",
    "                ).values[0],\n",
    "                3,\n",
    "            )\n",
    "            totalStructural += structureSumOneBldgType\n",
    "\n",
    "            contentSumOneBldgType = round(\n",
    "                (\n",
    "                    ((np.multiply(contentInterpSet, wp).sum()) * bldgValue[bldgType])\n",
    "                    / 10000\n",
    "                ).values[0]\n",
    "                * contentsPercentage,\n",
    "                3,\n",
    "            )\n",
    "            totalContents += contentSumOneBldgType\n",
    "\n",
    "        progress = (ticker / progressOutOf) * 100\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO \"flood_sim_result\" (sim_id, block_num, bldg_count, bldg_exposure, cont_exposure, total_exposure, struct_dmg, cont_dmg, total_dmg, bldgs_affected, population, affected_population)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "            \"\"\",\n",
    "            (\n",
    "                simId,\n",
    "                blockId,\n",
    "                buildingCount,\n",
    "                0,\n",
    "                0,\n",
    "                buildingValue,\n",
    "                int(totalStructural),\n",
    "                int(totalContents),\n",
    "                int(totalContents + totalStructural),\n",
    "                bldgs_affected,\n",
    "                blockPopulation,\n",
    "                affected_population,\n",
    "            ),\n",
    "        )\n",
    "        conn.commit()\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            UPDATE \"flood_simulation\"\n",
    "            SET sim_percent_completed = (%s)\n",
    "            WHERE sim_id = (%s)\n",
    "            \"\"\",\n",
    "            (progress, simId),\n",
    "        )\n",
    "        conn.commit()\n",
    "        service = os.environ.get('FLOOD_MAP_SERVICE')\n",
    "\n",
    "        legendBase = \"{service}&SERVICE=WMS&VERSION=1.3.0&REQUEST=getlegendgraphic&FORMAT=image/png&sld_version=1.1.0&map=/map/er2/flood.map&layer=\".format(service=service)\n",
    "        query_info_url = os.environ.get(\"ER2_API\")+\"/flood/query?id=\" + simId\n",
    "        actions = [\n",
    "            {\n",
    "                \"type\": \"load-layer\",\n",
    "                \"source\": [\n",
    "                    {\n",
    "                        \"legend_name\": \"Total Damage\",\n",
    "                        \"id\": simId + \"_total_dmg\",\n",
    "                        \"name\": \"total_dmg\",\n",
    "                        \"simId\": simId,\n",
    "                        \"serverType\": \"mapserver\",\n",
    "                        \"service\": service,\n",
    "                        \"styles\": \"\",\n",
    "                        \"type\": \"wms-layer\",\n",
    "                        \"query_info_url\": query_info_url,\n",
    "                        \"legend_url\": legendURLs['total_dmg']\n",
    "                    },\n",
    "                    {\n",
    "                        \"legend_name\": \"Buildings Affected\",\n",
    "                        \"id\": simId + \"_bldgs_affected\",\n",
    "                        \"name\": \"bldgs_affected\",\n",
    "                        \"simId\": simId,\n",
    "                        \"serverType\": \"mapserver\",\n",
    "                        \"service\": service,\n",
    "                        \"styles\": \"\",\n",
    "                        \"type\": \"wms-layer\",\n",
    "                        \"query_info_url\": query_info_url,\n",
    "                        \"legend_url\": legendURLs['bldgs_affected']\n",
    "                    },\n",
    "                    {\n",
    "                        \"legend_name\": \"Population\",\n",
    "                        \"id\": simId + \"_population\",\n",
    "                        \"name\": \"population\",\n",
    "                        \"simId\": simId,\n",
    "                        \"serverType\": \"mapserver\",\n",
    "                        \"service\": service,\n",
    "                        \"styles\": \"\",\n",
    "                        \"type\": \"wms-layer\",\n",
    "                        \"query_info_url\": query_info_url,\n",
    "                        \"legend_url\": legendURLs['population']\n",
    "                    },\n",
    "                    {\n",
    "                        \"legend_name\": \"Affected Population\",\n",
    "                        \"id\": simId + \"_affected_population\",\n",
    "                        \"name\": \"affected_population\",\n",
    "                        \"simId\": simId,\n",
    "                        \"serverType\": \"mapserver\",\n",
    "                        \"service\": service,\n",
    "                        \"styles\": \"\",\n",
    "                        \"type\": \"wms-layer\",\n",
    "                        \"query_info_url\": query_info_url,\n",
    "                        \"legend_url\": legendURLs['affected_population']\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        self.update_state(\n",
    "            state=\"PROGRESS\",\n",
    "            meta={\n",
    "                \"actions\": actions,\n",
    "                \"current\": ticker,\n",
    "                \"total\": progressOutOf,\n",
    "                \"status\": \"ongoing\",\n",
    "                \"progress\": progress,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"total\": int(totalStructural + totalContents),\n",
    "            \"structure\": int(totalStructural),\n",
    "            \"content\": int(totalContents),\n",
    "        }\n",
    "    damages = adjInventory.apply(computeDamages, progressOutOf=progressOutOf, axis=1)\n",
    "\n",
    "    logging.info(\"Damages computed.\")\n",
    "\n",
    "    self.update_state(\n",
    "        state=\"PROGRESS\",\n",
    "        meta={\n",
    "            \"current\": progressOutOf,\n",
    "            \"total\": progressOutOf,\n",
    "            \"status\": \"done\",\n",
    "            \"actions\": None,\n",
    "            \"progress\": 100,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Mark the simulation as complete in db\n",
    "    end_time = datetime.now()\n",
    "    simulationStatus = \"completed\"\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        UPDATE \"flood_simulation\"\n",
    "        SET sim_completed = (%s), sim_status= (%s)\n",
    "        WHERE sim_id = (%s)\n",
    "        \"\"\",\n",
    "        (end_time, simulationStatus, simId),\n",
    "    )\n",
    "    conn.commit()\n",
    "\n",
    "    logging.info(\"Closing db connection.\")\n",
    "    cur.close()\n",
    "    time.sleep(6)\n",
    "    return \"Simulation complete\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
